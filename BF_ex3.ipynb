{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b26c641112d8d71",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from pyparsing import results\n",
    "from shapely.geometry import Point\n",
    "import requests\n",
    "import glob\n",
    "import os\n",
    "import timeit\n",
    "import numpy as np\n",
    "from pandas import Timedelta"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "my_globals = {}\n",
    "exec(\"from osgeo import gdal\", my_globals)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f4cab2ed0562222",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "root = '/home/pier/'\n",
    "samples = 40"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9693363a792e0e2b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "gcp_total = gpd.read_file(r'data/gcp.shp', where=\"q_score='5'\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f11b76fb1d669276",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "random_points_gdf = gcp_total.sample(samples)\n",
    "random_points_gdf.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bffc49f25cf29b4a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "date_range = pd.date_range('2020-01-01', '2024-02-14')\n",
    "date_index = pd.DataFrame(date_range, columns=['date'])\n",
    "date_subset = date_index.sample(n=samples)\n",
    "date_subset.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eebf58382f402f56",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rnd = random_points_gdf.join(date_subset) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "556041ea551471c4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# base URL of the product catalogue\n",
    "catalogue_odata_url = \"https://catalogue.dataspace.copernicus.eu/odata/v1\"\n",
    "\n",
    "# search parameters\n",
    "collection_name = \"SENTINEL-2\"\n",
    "product_type = \"S2MSI2A\"\n",
    "max_cloud_cover = 100\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6eefcbc1114f7a1f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def path_builder(aoi, catalogue_odata_url, collection_name, product_type, max_cloud_cover, search_period_start, search_period_end, root):\n",
    "    search_query = f\"{catalogue_odata_url}/Products?$filter=Collection/Name eq '{collection_name}' and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq '{product_type}') and OData.CSC.Intersects(area=geography'SRID=4326;{aoi}') and ContentDate/Start gt {search_period_start} and ContentDate/Start lt {search_period_end}\"\n",
    "    \n",
    "    response = requests.get(search_query)\n",
    "    if response.status_code == 200:\n",
    "        response = response.json()\n",
    "        result = pd.DataFrame.from_dict(response[\"value\"])\n",
    "        if result.empty:\n",
    "            print(f\"No results for {aoi}\")\n",
    "            return None, None, None\n",
    "        else:\n",
    "            random.seed(1492)\n",
    "            \n",
    "            if len(result) > 1:\n",
    "                n = random.randint(0, result.shape[0]-1)\n",
    "            else:\n",
    "                n = 0\n",
    "                \n",
    "            product_name = result.iloc[n]['Name']\n",
    "            print(product_name)\n",
    "        \n",
    "            nm_component = product_name.split('_')\n",
    "            yr = nm_component[2][:4] \n",
    "            mm = nm_component[2][4:6]\n",
    "            dd = nm_component[2][6:8]\n",
    "            \n",
    "            zone = nm_component[5][1:3]\n",
    "            row = nm_component[5][3:4]\n",
    "            square = nm_component[5][4:6]\n",
    "            CDSE_path = glob.glob(os.path.join(root, 'CDSE', f'Sentinel-2/MSI/L2A/{yr}/{mm}/{dd}/{product_name}/GRANULE/*/IMG_DATA/R20m/*B07_20m.jp2'))[0]\n",
    "            AWS_path = os.path.join(root, 'AWS', f'tiles/{zone}/{row}/{square}/{yr}/{int(mm)}/{int(dd)}/0/R20m/B07.jp2')\n",
    "            return product_name, CDSE_path, AWS_path\n",
    "    else:\n",
    "        print(f'{response.status_code}')\n",
    "        return None, None, None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d6254c473d7a3e5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "results = []\n",
    "repeat_n = 10\n",
    "number_n = 1\n",
    "dd_number = 1\n",
    "\n",
    "for row in rnd.iterrows():\n",
    "    point = row[1].get(key = 'geometry')\n",
    "    date = row[1].get(key = 'date')\n",
    "\n",
    "    search_period_start = (date - Timedelta(dd_number, unit='day')).strftime('%Y-%m-%dT00:00:00.000Z')\n",
    "    search_period_end = (date + Timedelta(dd_number, unit='day')).strftime('%Y-%m-%dT00:00:00.000Z')\n",
    "    \n",
    "    product_name, CDSE_path, AWS_path = path_builder(point, catalogue_odata_url, collection_name, product_type, max_cloud_cover, search_period_start, search_period_end, root)\n",
    "\n",
    "    if product_name:\n",
    "\n",
    "        timing_CDSE = timeit.repeat(f'gdal.Info(\\'{CDSE_path}\\')',\n",
    "                               #setup='from osgeo import gdal', \n",
    "                               repeat=repeat_n, \n",
    "                               number=number_n, \n",
    "                               globals=my_globals)\n",
    "        timing_CDSE = np.array(timing_CDSE)/number_n\n",
    "        mean_CDSE = np.mean(timing_CDSE).round(3)\n",
    "        std_CDSE = np.std(timing_CDSE).round(3)\n",
    "        min_CDSE = np.min(timing_CDSE).round(3)\n",
    "        max_CDSE = np.max(timing_CDSE).round(3)\n",
    "\n",
    "        timing_AWS = timeit.repeat(f'gdal.Info(\\'{AWS_path}\\')',\n",
    "                               #setup='from osgeo import gdal', \n",
    "                               repeat=repeat_n, \n",
    "                               number=number_n, \n",
    "                               globals=my_globals)\n",
    "        timing_AWS = np.array(timing_AWS)/number_n\n",
    "        mean_aws = np.mean(timing_AWS).round(3)\n",
    "        std_aws = np.std(timing_AWS).round(3)\n",
    "        min_AWS = np.min(timing_AWS).round(3)\n",
    "        max_AWS = np.max(timing_AWS).round(3)\n",
    "\n",
    "        results.append([product_name, mean_CDSE, min_CDSE, max_CDSE, std_CDSE, mean_aws, min_AWS, max_AWS, std_aws])\n",
    "results_df = pd.DataFrame(results, columns=['product_name', 'mean_CDSE', 'min_CDSE', 'max_CDSE', 'std_CDSE', 'mean_AWS', 'min_AWS', 'max_AWS', 'std_AWS'])\n",
    "\n",
    "results_df.to_csv('CDSE_AWS.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6a2ab412942c5db",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bcc63230f1c6b4d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
